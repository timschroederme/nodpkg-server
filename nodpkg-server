#!/usr/bin/env python3

import glob
import json
from datetime import datetime
import requests
from lxml import html
import os.path

DATEFORMAT = "%Y-%m-%d %H:%M:%S"
NOPACKAGES_PATH = "nopackages/*.json"
LATEST_VERSIONS = ".latest-versions"
LATEST_CHECKS = ".latest-checks"


def scrape(url, xpath):
    response = requests.get(url)
    tree = html.fromstring(response.content)
    path = tree.xpath(xpath + "/text()")
    raw = path[0]
    if len(path) > 1:
        for r in path:
            r_clean = r.strip().replace('\n', '').replace('\r', '')
            if len(r_clean) > 0:
                raw = r_clean
    raw_version = raw.strip().replace('\n', ' ').replace('\r', '')

    first = -1
    last = 0
    for i, c in enumerate(raw_version):
        if c.isdigit():
            if first == -1:
                first = i
            last = i

    version = raw_version[first:last + 1]
    return version


def load_latest_versions():
    if os.path.exists(LATEST_VERSIONS):
        with open(LATEST_VERSIONS, 'r') as file:
            return json.loads(file.read())
    else:
        return {}


def store_latest_versions(versions):
    with open(LATEST_VERSIONS, 'w') as file:
        file.write(json.dumps(versions, indent=2))


def load_latest_checks():
    if os.path.exists(LATEST_CHECKS):
        with open(LATEST_CHECKS, 'r') as file:
            return json.loads(file.read())
    else:
        return {}


def store_latest_checks(checks):
    with open(LATEST_CHECKS, 'w') as file:
        file.write(json.dumps(checks, indent=2))


def broadcast_update():
    print("update!")


# Main
any_change = False
latest_versions = load_latest_versions()
latest_checks = load_latest_checks()

# Main Update Loop
for filename in glob.glob(NOPACKAGES_PATH):
    with open(filename) as f:
        data = json.load(f)
        name = data['name']
        print(name + "..", end='')

        # check if project is due for a check
        needs_check = True
        if name in latest_checks:
            stamp = datetime.strptime(latest_checks[name], DATEFORMAT)
            delta = datetime.now() - stamp
            h = divmod(delta.total_seconds(), 3600)[0]  # hours
            if h < 12:
                needs_check = False
                print (" skip")

        if needs_check:
            # check if new release is available
            v = scrape(data['url'], data['xpath'])
            if name in latest_versions:
                if latest_versions[name] == v:
                    print (" ok")
                else:
                    print (" new release")
                    latest_versions[name] = v
                    broadcast_update()
            else:
                print (" initial check")
                latest_versions[name] = v
            latest_checks[name] = datetime.now().strftime(DATEFORMAT)

# Store updated metadata
store_latest_versions(latest_versions)
store_latest_checks(latest_checks)
